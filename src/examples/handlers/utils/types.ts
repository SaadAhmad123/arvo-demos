import type { InferVersionedArvoContract } from 'arvo-core';
import type { AnyVersionedContract } from '../types';
import type { Span } from '@opentelemetry/api';

/**
 * Message content representing the result of a completed tool execution.
 *
 * Used when an LLM receives the output from a previously requested tool call.
 * The content is typically JSON-serialized data from the tool's execution.
 */
export type AgenticToolResultMessageContent = {
  type: 'tool_result';
  /** Unique identifier linking this result back to the original tool request */
  tool_use_id: string;
  /** JSON-serialized output data returned by the executed tool */
  content: string;
};

/**
 * Message content representing a request to execute a specific tool.
 *
 * Generated by LLMs when they determine a tool call is needed to fulfill
 * a user request. Contains all necessary parameters for tool execution.
 */
export type AgenticToolCallMessageContent = {
  type: 'tool_use';
  /** Unique identifier for tracking this specific tool request */
  id: string;
  /** Name/type of the tool to execute (maps to Arvo service contract types) */
  name: string;
  /** Parameters to pass to the tool, structured according to the tool's contract */
  input: object;
};

/**
 * Message content containing plain text communication.
 *
 * Represents standard conversational content without any tool interaction.
 * Used for both user input and LLM text responses.
 */
export type AgenticTextMessageContent = {
  type: 'text';
  /** The actual text content of the message */
  content: string;
};

/**
 * Union of all possible message content types in agentic conversations.
 *
 * Supports the three fundamental message patterns:
 * - Text for natural language communication
 * - Tool calls for LLM-initiated service requests
 * - Tool results for service response data
 */
export type AgenticMessageContent =
  | AgenticTextMessageContent
  | AgenticToolCallMessageContent
  | AgenticToolResultMessageContent;

/**
 * Input parameters for calling an agentic LLM service.
 *
 * Provides the LLM with conversation context, available tools, and prompt templates
 * to generate appropriate responses or tool requests.
 *
 * @template TTools - Mapping of tool names to their Arvo contract definitions
 * @template TPrompts - Collection of prompt template functions for different scenarios
 */
export type CallAgenticLLMParam<
  TTools extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
  // biome-ignore lint/suspicious/noExplicitAny: Needs to general
  TPrompts extends Record<string, (...args: any[]) => string> = Record<string, (...args: any[]) => string>,
> = {
  /**
   * Indicates whether this is conversation initialization or processing tool results.
   * - 'init': Start of conversation with user message
   * - 'tool_results': Continuation after receiving tool execution results
   */
  type: 'init' | 'tool_results';

  /**
   * Complete conversation history in chronological order.
   */
  messages: {
    role: 'user' | 'assistant';
    content: AgenticMessageContent[];
  }[];

  /**
   * Available tools/services the LLM can invoke.
   *
   * Each tool is defined by its Arvo contract, providing schema validation
   * and type safety for tool parameter generation.
   */
  tools: TTools;

  /** Collection of prompt template functions for different conversation scenarios */
  prompts: TPrompts;

  /** The current OTEL span to record logs to. */
  span: Span;
};

/**
 * Response from an agentic LLM service call.
 *
 * The LLM can either provide a direct text response or request tool executions.
 * These are mutually exclusive - if tool requests are present, response must be null.
 *
 * @template TTools - Mapping of tool names to their Arvo contract definitions
 */
export type CallAgenticLLMOutput<
  TTools extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
> = {
  /**
   * Tool execution requests generated by the LLM.
   *
   * Each request is fully typed according to its corresponding Arvo contract,
   * ensuring type safety between LLM tool selection and service execution.
   * Null when the LLM provides a direct text response instead.
   */
  toolRequests: Array<
    {
      [K in keyof TTools]: {
        type: InferVersionedArvoContract<TTools[K]>['accepts']['type'];
        data: InferVersionedArvoContract<TTools[K]>['accepts']['data'];
        id: string;
      };
    }[keyof TTools]
  > | null;

  /**
   * Direct text response from the LLM.
   *
   * Present when the LLM can fulfill the request without tool usage.
   * Must be null when toolRequests are present.
   */
  response: string | null;

  /**
   * Count of each tool type requested in this call.
   *
   * Used for tracking tool usage patterns, debugging, and ensuring
   * all expected tool responses are collected before proceeding.
   */
  toolTypeCount: Record<string, number>;

  usage?: {
    tokens: {
      prompt: number;
      completion: number;
    };
  };
};

/**
 * Function signature for calling an agentic LLM service.
 *
 * Implementations should handle the conversation context, tool definitions,
 * and return either a text response or structured tool requests.
 *
 * @template TTools - Available tools/services for the LLM to invoke
 * @template TPrompts - Prompt template functions for conversation scenarios
 */
export type CallAgenticLLM<
  TTools extends Record<string, AnyVersionedContract> = Record<string, AnyVersionedContract>,
  // biome-ignore lint/suspicious/noExplicitAny: Needs to be general
  TPrompts extends Record<string, (...args: any[]) => string> = Record<string, (...args: any[]) => string>,
> = (param: CallAgenticLLMParam<TTools, TPrompts>) => Promise<CallAgenticLLMOutput<TTools>>;

/**
 * Configuration parameters for creating an agentic resumable orchestrator.
 *
 * Defines all components needed to create an AI agent that can engage in
 * conversations, make tool decisions, and execute workflows through Arvo's
 * event-driven architecture.
 *
 * @template TName - String literal type for the agent's unique identifier
 * @template TServices - Record of Arvo service contracts available as tools
 * @template TPrompts - Collection of prompt template functions
 */
export type CreateAgenticResumableParams<
  TName extends string,
  TServices extends Record<string, AnyVersionedContract>,
  // biome-ignore lint/suspicious/noExplicitAny: Needs to general
  TPrompts extends Record<string, (...args: any[]) => string>,
> = {
  /**
   * Unique name for this agent instance.
   * Used in generated contract URIs and for agent identification.
   */
  name: TName;

  /**
   * Function implementing the LLM service integration.
   */
  agenticLLMCaller: CallAgenticLLM<TServices, TPrompts>;

  /**
   * Arvo service contracts available as tools for the agent.
   *
   * Each contract defines a service the LLM can invoke, with full
   * type safety and schema validation enforced by Arvo.
   */
  services: TServices;

  /**
   * Optional domain routing configuration for services.
   *
   * Maps service event types to specific processing domains,
   * enabling advanced routing patterns
   */
  serviceDomains?: Record<{ [K in keyof TServices]: TServices[K]['accepts']['type'] }[keyof TServices], string[]>;

  /**
   * Prompt template functions for different conversation scenarios.
   *
   * Provides reusable prompt generation for system messages,
   * tool descriptions, and context-specific instructions.
   */
  prompts: TPrompts;
};
